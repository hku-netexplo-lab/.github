# NETEXPLO at The University of Hong Kong

Welcome to NETEXPLO lab led by Dr. Chuan Wu in the Department of Computer Science at The University of Hong Kong. Our group is dedicated to advancing the fields of:

- **Distributed Machine Learning Systems**
- **Efficient AI**
- **Cloud Computing Systems**
- **Computer Networking**
- **Big Data Analytics**

Our work aims to develop innovative solutions that enhance the performance, scalability, and efficiency of computing systems.

## Selected Publications

**[EuroSys'25]** HybridFlow: A Flexible and Efficient RLHF Framework.  
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/volcengine/verl)

**[NSDI'25]** ByteCheckpoint: A Unified Checkpointing System for Large Foundation Model Development. 
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/ByteDance-Seed/ByteCheckpoint)

**[SOSP'25]** DCP: Addressing Input Dynamism In Long-Context Training via Dynamic Context Parallelism. 

**[SOSP'25]** Robust LLM Training Infrastructure at ByteDance.  

**[INFOCOM'25]** Optimizing Distributed Deployment of Mixture-of-Experts Model Inference in Serverless Computing.  

**[EuroSys'24]** DynaPipe: Optimizing Multi-task Training through Dynamic Pipelines. 

**[EuroSys'24]** CDMPP: A Device-Model Agnostic Framework for Latency Prediction of Tensor Programs. 

**[EuroSys'24]** HAP: SPMD DNN Training on Heterogeneous GPU Clusters with Automated Program Synthesis. 
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/alibaba/hap)

**[SOSP'19]** A Generic Communication Scheduler for Distributed DNN Training Acceleration.

**[EuroSys'18]** Optimus: An Efficient Dynamic Resource Scheduler for Deep Learning Clusters.

<!-- **[VLDB'25]** Heta: Distributed Training of Heterogeneous Graph Neural Networks
*The University of Hong Kong*  
[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/jasperzhong/heta) -->

